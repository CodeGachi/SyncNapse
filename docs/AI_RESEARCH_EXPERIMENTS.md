# AI ê¸°ëŠ¥ ì—°êµ¬ ì‹¤í—˜ ì„¤ê³„ì„œ

> AI ê²½ì§„ëŒ€íšŒ ë…¼ë¬¸ì„ ìœ„í•œ ì²´ê³„ì ì¸ ì‹¤í—˜ ì„¤ê³„

## ğŸ“‹ ëª©ì°¨

1. [ì‹¤í—˜ 1: Whisper vs Web Speech API ë¹„êµ](#ì‹¤í—˜-1-whisper-vs-web-speech-api-ë¹„êµ)
2. [ì‹¤í—˜ 2: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì „ëµ í‰ê°€](#ì‹¤í—˜-2-í•˜ì´ë¸Œë¦¬ë“œ-ê²€ìƒ‰-ì „ëµ-í‰ê°€)
3. [ì‹¤í—˜ 3: Multi-modal RAG íš¨ê³¼ ì¸¡ì •](#ì‹¤í—˜-3-multi-modal-rag-íš¨ê³¼-ì¸¡ì •)
4. [ì‹¤í—˜ 4: ê°œì¸í™” í•™ìŠµ íš¨ê³¼ ë¶„ì„](#ì‹¤í—˜-4-ê°œì¸í™”-í•™ìŠµ-íš¨ê³¼-ë¶„ì„)
5. [ì‹¤í—˜ 5: ì‚¬ìš©ì ê²½í—˜ í‰ê°€](#ì‹¤í—˜-5-ì‚¬ìš©ì-ê²½í—˜-í‰ê°€)

---

## ì‹¤í—˜ 1: Whisper vs Web Speech API ë¹„êµ

### ğŸ“Š ì—°êµ¬ ì§ˆë¬¸

**RQ1**: OpenAI Whisperê°€ Web Speech API ëŒ€ë¹„ ê°•ì˜ ì „ì‚¬ì˜ ì •í™•ë„ë¥¼ ì–¼ë§ˆë‚˜ í–¥ìƒì‹œí‚¤ëŠ”ê°€?

**RQ2**: ì „ë¬¸ ìš©ì–´ê°€ ë§ì€ í•™ìˆ  ê°•ì˜ì—ì„œ ë‘ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ ì°¨ì´ëŠ” ì–¼ë§ˆë‚˜ ë˜ëŠ”ê°€?

### ğŸ¯ ê°€ì„¤

- **H1**: Whisperê°€ Web Speech APIë³´ë‹¤ WER(Word Error Rate)ê°€ ìµœì†Œ 20% ë‚®ì„ ê²ƒì´ë‹¤.
- **H2**: ì „ë¬¸ ìš©ì–´ ì¸ì‹ë¥ ì—ì„œ Whisperê°€ ìµœì†Œ 30% ë†’ì„ ê²ƒì´ë‹¤.
- **H3**: ì‹¤ì‹œê°„ ì²˜ë¦¬ ì§€ì—°(latency)ì€ Whisperê°€ 2-3ë°° ë†’ì„ ê²ƒì´ë‹¤.

### ğŸ“ ì‹¤í—˜ ì„¤ê³„

#### ë°ì´í„°ì…‹ êµ¬ì„±

```
ì´ 60ê°œ ê°•ì˜ ìƒ˜í”Œ (ê° 5-10ë¶„)

ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:
- ì¼ë°˜ êµì–‘ (20ê°œ): í•œêµ­ì‚¬, ì² í•™, ê²½ì œí•™
- STEM (20ê°œ): ìˆ˜í•™, ë¬¼ë¦¬í•™, ì»´í“¨í„°ê³¼í•™
- ì „ë¬¸ ë¶„ì•¼ (20ê°œ): ì˜í•™, ë²•í•™, ê³µí•™

ìŒì§ˆ ì¡°ê±´:
- ê³ í’ˆì§ˆ (20ê°œ): ìŠ¤íŠœë””ì˜¤ ë…¹ìŒ
- ì¤‘í’ˆì§ˆ (20ê°œ): ê°•ì˜ì‹¤ ë…¹ìŒ
- ì €í’ˆì§ˆ (20ê°œ): ì¡ìŒ í¬í•¨
```

#### ì‹¤í—˜ ì ˆì°¨

**1ë‹¨ê³„: Ground Truth ìƒì„±**
```python
# ì‚¬ëŒì´ ì§ì ‘ ì „ì‚¬í•˜ì—¬ ì •ë‹µ ë°ì´í„° ìƒì„±
# ì „ë¬¸ ì „ì‚¬ ì„œë¹„ìŠ¤ í™œìš© ë˜ëŠ” ì—°êµ¬íŒ€ ì§ì ‘ ì „ì‚¬
```

**2ë‹¨ê³„: ì‹œìŠ¤í…œ ì „ì‚¬**
```typescript
// ê° ìƒ˜í”Œì— ëŒ€í•´ ë‘ ì‹œìŠ¤í…œìœ¼ë¡œ ì „ì‚¬
for (const sample of dataset) {
  // Web Speech API ì „ì‚¬
  const webSpeechResult = await transcribeWithWebSpeech(sample);
  
  // Whisper ì „ì‚¬
  const whisperResult = await transcribeWithWhisper(sample);
  
  // ê²°ê³¼ ì €ì¥
  await saveResults({
    sampleId: sample.id,
    groundTruth: sample.groundTruth,
    webSpeech: webSpeechResult,
    whisper: whisperResult,
  });
}
```

**3ë‹¨ê³„: í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚°**

#### í‰ê°€ ì§€í‘œ

**1. WER (Word Error Rate)**
```python
WER = (S + D + I) / N

S: ëŒ€ì²´ëœ ë‹¨ì–´ ìˆ˜ (Substitutions)
D: ì‚­ì œëœ ë‹¨ì–´ ìˆ˜ (Deletions)
I: ì‚½ì…ëœ ë‹¨ì–´ ìˆ˜ (Insertions)
N: ì „ì²´ ë‹¨ì–´ ìˆ˜
```

**ì½”ë“œ ì˜ˆì‹œ:**
```typescript
import leven from 'leven'; // Levenshtein distance

function calculateWER(reference: string, hypothesis: string): number {
  const refWords = reference.split(' ');
  const hypWords = hypothesis.split(' ');
  
  const distance = leven(refWords.join(''), hypWords.join(''));
  return distance / refWords.length;
}
```

**2. ì „ë¬¸ ìš©ì–´ ì •í™•ë„**
```typescript
interface TermAccuracy {
  term: string;
  occurrences: number;
  correctRecognitions: number;
  accuracy: number;
}

function evaluateTermAccuracy(
  groundTruth: string,
  transcription: string,
  technicalTerms: string[],
): TermAccuracy[] {
  const results: TermAccuracy[] = [];
  
  for (const term of technicalTerms) {
    const truthCount = (groundTruth.match(new RegExp(term, 'g')) || []).length;
    const transCount = (transcription.match(new RegExp(term, 'g')) || []).length;
    
    results.push({
      term,
      occurrences: truthCount,
      correctRecognitions: Math.min(truthCount, transCount),
      accuracy: truthCount > 0 ? Math.min(truthCount, transCount) / truthCount : 0,
    });
  }
  
  return results;
}
```

**3. ì‹¤ì‹œê°„ ì„±ëŠ¥ (RTF - Real-Time Factor)**
```typescript
RTF = Processing Time / Audio Duration

// RTF < 1.0 ì´ë©´ ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥
// RTF = 0.5 ì´ë©´ 10ì´ˆ ì˜¤ë””ì˜¤ë¥¼ 5ì´ˆì— ì²˜ë¦¬

function calculateRTF(processingTime: number, audioDuration: number): number {
  return processingTime / audioDuration;
}
```

**4. ë¹„ìš© ë¶„ì„**
```typescript
interface CostAnalysis {
  system: 'WebSpeech' | 'Whisper';
  audioHours: number;
  costPerHour: number;
  totalCost: number;
}

// Web Speech API: ë¬´ë£Œ (ë¸Œë¼ìš°ì € ë‚´ì¥)
// Whisper API: $0.006 / minute = $0.36 / hour
```

### ğŸ“ˆ ì˜ˆìƒ ê²°ê³¼

```
ì˜ˆìƒ WER (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ):
- Web Speech API: 15-25%
- Whisper: 5-10%

ì˜ˆìƒ ì „ë¬¸ ìš©ì–´ ì •í™•ë„:
- Web Speech API: 60-70%
- Whisper: 85-95%

ì˜ˆìƒ RTF:
- Web Speech API: 0.1-0.3 (ì‹¤ì‹œê°„)
- Whisper: 0.5-1.5 (ì¤€ì‹¤ì‹œê°„)
```

### ğŸ“Š ê²°ê³¼ ì‹œê°í™”

```python
import matplotlib.pyplot as plt
import seaborn as sns

# 1. WER ë¹„êµ ë°•ìŠ¤í”Œë¡¯
plt.figure(figsize=(10, 6))
sns.boxplot(data=results, x='category', y='wer', hue='system')
plt.title('WER Comparison by Category')
plt.savefig('wer_comparison.png')

# 2. ì „ë¬¸ ìš©ì–´ ì •í™•ë„ íˆíŠ¸ë§µ
plt.figure(figsize=(12, 8))
sns.heatmap(term_accuracy_matrix, annot=True, fmt='.2f')
plt.title('Technical Term Recognition Accuracy')
plt.savefig('term_accuracy.png')

# 3. ìŒì§ˆë³„ ì„±ëŠ¥
plt.figure(figsize=(10, 6))
plt.plot(audio_quality, web_speech_performance, label='Web Speech')
plt.plot(audio_quality, whisper_performance, label='Whisper')
plt.legend()
plt.title('Performance by Audio Quality')
plt.savefig('quality_performance.png')
```

---

## ì‹¤í—˜ 2: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì „ëµ í‰ê°€

### ğŸ“Š ì—°êµ¬ ì§ˆë¬¸

**RQ1**: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì´ ìˆœìˆ˜ ë²¡í„° ê²€ìƒ‰ ëŒ€ë¹„ ê²€ìƒ‰ í’ˆì§ˆì„ ì–¼ë§ˆë‚˜ í–¥ìƒì‹œí‚¤ëŠ”ê°€?

**RQ2**: ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ìµœì ì˜ ê²€ìƒ‰ ì „ëµì€ ë¬´ì—‡ì¸ê°€?

### ğŸ¯ ê°€ì„¤

- **H1**: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì´ ìˆœìˆ˜ ë²¡í„° ê²€ìƒ‰ ëŒ€ë¹„ MRRì´ 15% ì´ìƒ ë†’ì„ ê²ƒì´ë‹¤.
- **H2**: ì‚¬ì‹¤ ê¸°ë°˜ ì§ˆë¬¸ì—ì„œëŠ” í‚¤ì›Œë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜ë¥¼ ë†’ì¼ìˆ˜ë¡ ì„±ëŠ¥ì´ í–¥ìƒë  ê²ƒì´ë‹¤.
- **H3**: ê°œë… ì„¤ëª… ì§ˆë¬¸ì—ì„œëŠ” ë²¡í„° ê²€ìƒ‰ ê°€ì¤‘ì¹˜ë¥¼ ë†’ì¼ìˆ˜ë¡ ì„±ëŠ¥ì´ í–¥ìƒë  ê²ƒì´ë‹¤.

### ğŸ“ ì‹¤í—˜ ì„¤ê³„

#### ë°ì´í„°ì…‹ êµ¬ì„±

**1. ê°•ì˜ ë…¸íŠ¸ ë°ì´í„°**
```
10ê°œ ê³¼ëª© Ã— 5ê°œ ê°•ì˜ = 50ê°œ ë…¸íŠ¸
- ê° ë…¸íŠ¸ë‹¹ 30-50 í˜ì´ì§€ PDF
- ìŒì„± ì „ì‚¬ í¬í•¨
- í•™ìƒ í•„ê¸° í¬í•¨
```

**2. ì§ˆë¬¸ ë°ì´í„°ì…‹ (ì´ 500ê°œ)**
```typescript
interface Question {
  id: string;
  text: string;
  type: QuestionType;
  relevantDocs: string[]; // Ground truth
  difficulty: 'easy' | 'medium' | 'hard';
}

enum QuestionType {
  FACTUAL = 'factual',           // ì‚¬ì‹¤ í™•ì¸: "ê²½ì‚¬í•˜ê°•ë²•ì˜ í•™ìŠµë¥ ì€?"
  CONCEPTUAL = 'conceptual',     // ê°œë… ì„¤ëª…: "ê²½ì‚¬í•˜ê°•ë²•ì´ë€?"
  COMPARISON = 'comparison',     // ë¹„êµ: "Aì™€ Bì˜ ì°¨ì´ëŠ”?"
  APPLICATION = 'application',   // ì‘ìš©: "ì´ê±¸ ì‹¤ì œë¡œ ì–´ë–»ê²Œ ì‚¬ìš©?"
  ANALYSIS = 'analysis',         // ë¶„ì„: "ì™œ ì´ëŸ° ê²°ê³¼ê°€?"
}
```

**ì§ˆë¬¸ ì˜ˆì‹œ:**
```json
[
  {
    "id": "q001",
    "text": "ê²½ì‚¬í•˜ê°•ë²•(Gradient Descent)ì´ë€ ë¬´ì—‡ì¸ê°€?",
    "type": "conceptual",
    "relevantDocs": ["note-001-page-15", "note-001-page-16"],
    "difficulty": "medium"
  },
  {
    "id": "q002",
    "text": "í•™ìŠµë¥ (learning rate)ì˜ ê°’ì€ ë¬´ì—‡ì¸ê°€?",
    "type": "factual",
    "relevantDocs": ["note-001-page-17"],
    "difficulty": "easy"
  },
  {
    "id": "q003",
    "text": "ë°°ì¹˜ ê²½ì‚¬í•˜ê°•ë²•ê³¼ í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²•ì˜ ì°¨ì´ì ì€?",
    "type": "comparison",
    "relevantDocs": ["note-001-page-18", "note-001-page-19"],
    "difficulty": "hard"
  }
]
```

#### ì‹¤í—˜ ì¡°ê±´

**ê²€ìƒ‰ ì „ëµ ë¹„êµ:**
```typescript
const strategies = [
  { name: 'Vector Only', vectorWeight: 1.0, keywordWeight: 0.0 },
  { name: 'Keyword Only', vectorWeight: 0.0, keywordWeight: 1.0 },
  { name: 'Hybrid 50-50', vectorWeight: 0.5, keywordWeight: 0.5 },
  { name: 'Hybrid 60-40', vectorWeight: 0.6, keywordWeight: 0.4 },
  { name: 'Hybrid 70-30', vectorWeight: 0.7, keywordWeight: 0.3 },
  { name: 'Adaptive', vectorWeight: 'auto', keywordWeight: 'auto' }, // ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ìë™ ì¡°ì ˆ
];
```

#### í‰ê°€ ì§€í‘œ

**1. MRR (Mean Reciprocal Rank)**
```typescript
function calculateMRR(results: SearchResult[][]): number {
  let sum = 0;
  
  for (const result of results) {
    // ì²« ë²ˆì§¸ ê´€ë ¨ ë¬¸ì„œì˜ ìˆœìœ„ ì°¾ê¸°
    const firstRelevantIndex = result.findIndex(doc => doc.isRelevant);
    
    if (firstRelevantIndex >= 0) {
      sum += 1 / (firstRelevantIndex + 1);
    }
  }
  
  return sum / results.length;
}

// ì˜ˆì‹œ:
// ì§ˆë¬¸ 1: ê´€ë ¨ ë¬¸ì„œê°€ 1ë²ˆì§¸ â†’ RR = 1/1 = 1.0
// ì§ˆë¬¸ 2: ê´€ë ¨ ë¬¸ì„œê°€ 3ë²ˆì§¸ â†’ RR = 1/3 = 0.33
// ì§ˆë¬¸ 3: ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ â†’ RR = 0
// MRR = (1.0 + 0.33 + 0) / 3 = 0.44
```

**2. NDCG@K (Normalized Discounted Cumulative Gain)**
```typescript
function calculateNDCG(results: SearchResult[], k: number = 5): number {
  // DCG (ì‹¤ì œ ìˆœìœ„)
  let dcg = 0;
  for (let i = 0; i < Math.min(k, results.length); i++) {
    const relevance = results[i].relevanceScore; // 0-3 scale
    dcg += (Math.pow(2, relevance) - 1) / Math.log2(i + 2);
  }
  
  // IDCG (ì´ìƒì ì¸ ìˆœìœ„)
  const idealResults = [...results].sort((a, b) => b.relevanceScore - a.relevanceScore);
  let idcg = 0;
  for (let i = 0; i < Math.min(k, idealResults.length); i++) {
    const relevance = idealResults[i].relevanceScore;
    idcg += (Math.pow(2, relevance) - 1) / Math.log2(i + 2);
  }
  
  return idcg > 0 ? dcg / idcg : 0;
}
```

**3. Precision@K & Recall@K**
```typescript
function calculatePrecisionRecall(
  results: SearchResult[],
  groundTruth: string[],
  k: number,
): { precision: number; recall: number } {
  const topK = results.slice(0, k);
  const retrieved = new Set(topK.map(r => r.id));
  const relevant = new Set(groundTruth);
  
  const intersection = new Set([...retrieved].filter(x => relevant.has(x)));
  
  const precision = intersection.size / retrieved.size;
  const recall = intersection.size / relevant.size;
  
  return { precision, recall };
}
```

#### ì‹¤í—˜ ì ˆì°¨

```typescript
// í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
async function evaluateSearchStrategies() {
  const results = [];
  
  for (const strategy of strategies) {
    console.log(`Testing strategy: ${strategy.name}`);
    
    const metrics = {
      mrr: 0,
      ndcg: 0,
      precision: 0,
      recall: 0,
      responseTime: 0,
    };
    
    for (const question of questions) {
      const startTime = Date.now();
      
      // ê²€ìƒ‰ ìˆ˜í–‰
      const searchResults = await hybridSearch.search(
        question.text,
        documents,
        {
          vectorWeight: strategy.vectorWeight,
          keywordWeight: strategy.keywordWeight,
          topK: 10,
        },
      );
      
      const responseTime = Date.now() - startTime;
      
      // ë©”íŠ¸ë¦­ ê³„ì‚°
      const rr = calculateReciprocalRank(searchResults, question.relevantDocs);
      const ndcg = calculateNDCG(searchResults, 5);
      const { precision, recall } = calculatePrecisionRecall(
        searchResults,
        question.relevantDocs,
        5,
      );
      
      metrics.mrr += rr;
      metrics.ndcg += ndcg;
      metrics.precision += precision;
      metrics.recall += recall;
      metrics.responseTime += responseTime;
    }
    
    // í‰ê·  ê³„ì‚°
    const avgMetrics = {
      strategy: strategy.name,
      mrr: metrics.mrr / questions.length,
      ndcg: metrics.ndcg / questions.length,
      precision: metrics.precision / questions.length,
      recall: metrics.recall / questions.length,
      avgResponseTime: metrics.responseTime / questions.length,
    };
    
    results.push(avgMetrics);
  }
  
  return results;
}
```

### ğŸ“ˆ ì˜ˆìƒ ê²°ê³¼

```
ì˜ˆìƒ MRR:
- Vector Only: 0.65
- Keyword Only: 0.55
- Hybrid 60-40: 0.75
- Adaptive: 0.80

ì§ˆë¬¸ ìœ í˜•ë³„ ìµœì  ì „ëµ:
- Factual: Keyword-heavy (30-70)
- Conceptual: Vector-heavy (70-30)
- Comparison: Balanced (50-50)
- Application: Vector-heavy (70-30)
- Analysis: Vector-heavy (80-20)
```

### ğŸ“Š ê²°ê³¼ ì‹œê°í™”

```python
import pandas as pd
import matplotlib.pyplot as plt

# 1. ì „ëµë³„ ë©”íŠ¸ë¦­ ë¹„êµ
df = pd.DataFrame(results)
df.plot(x='strategy', y=['mrr', 'ndcg', 'precision', 'recall'], kind='bar')
plt.title('Search Strategy Comparison')
plt.savefig('strategy_comparison.png')

# 2. ì§ˆë¬¸ ìœ í˜•ë³„ ì„±ëŠ¥
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
for i, qtype in enumerate(QuestionType):
    ax = axes[i // 3, i % 3]
    type_results = df[df['question_type'] == qtype]
    type_results.plot(x='strategy', y='mrr', kind='bar', ax=ax)
    ax.set_title(f'{qtype} Questions')
plt.savefig('question_type_performance.png')

# 3. ê°€ì¤‘ì¹˜ íˆíŠ¸ë§µ
weights = np.linspace(0, 1, 11)
performance_matrix = np.zeros((11, 11))

for i, vec_w in enumerate(weights):
    for j, key_w in enumerate(weights):
        if vec_w + key_w == 1.0:
            performance_matrix[i, j] = run_experiment(vec_w, key_w)

sns.heatmap(performance_matrix, annot=True)
plt.xlabel('Keyword Weight')
plt.ylabel('Vector Weight')
plt.savefig('weight_heatmap.png')
```

---

## ì‹¤í—˜ 3: Multi-modal RAG íš¨ê³¼ ì¸¡ì •

### ğŸ“Š ì—°êµ¬ ì§ˆë¬¸

**RQ1**: ì´ë¯¸ì§€ ë¶„ì„ì„ í†µí•©í•œ Multi-modal RAGê°€ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•˜ëŠ” RAG ëŒ€ë¹„ ì •í™•ë„ë¥¼ ì–¼ë§ˆë‚˜ í–¥ìƒì‹œí‚¤ëŠ”ê°€?

**RQ2**: ì–´ë–¤ ìœ í˜•ì˜ ì§ˆë¬¸ì—ì„œ ì´ë¯¸ì§€ ë¶„ì„ì´ ê°€ì¥ íš¨ê³¼ì ì¸ê°€?

### ğŸ¯ ê°€ì„¤

- **H1**: ì°¨íŠ¸/ê·¸ë˜í”„ ê´€ë ¨ ì§ˆë¬¸ì—ì„œ Multi-modal RAGê°€ 50% ì´ìƒ ì •í™•ë„ í–¥ìƒ
- **H2**: ìˆ˜ì‹ í¬í•¨ ì§ˆë¬¸ì—ì„œ 30% ì´ìƒ ì •í™•ë„ í–¥ìƒ
- **H3**: ì¼ë°˜ í…ìŠ¤íŠ¸ ì§ˆë¬¸ì—ì„œëŠ” ë‘ ë°©ë²• ê°„ ìœ ì˜ë¯¸í•œ ì°¨ì´ ì—†ìŒ

### ğŸ“ ì‹¤í—˜ ì„¤ê³„

#### ë°ì´í„°ì…‹

**1. ê°•ì˜ ìë£Œ (20ê°œ)**
```
ì‹œê° ìë£Œê°€ í’ë¶€í•œ ê³¼ëª©:
- í†µê³„í•™ (ê·¸ë˜í”„, ì°¨íŠ¸)
- ë¬¼ë¦¬í•™ (ë‹¤ì´ì–´ê·¸ë¨, ìˆ˜ì‹)
- ìƒë¬¼í•™ (ê·¸ë¦¼, êµ¬ì¡°ë„)
- ìˆ˜í•™ (ìˆ˜ì‹, ì¦ëª…)
```

**2. ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ (ì´ 200ê°œ)**
```typescript
enum VisualQuestionType {
  CHART = 'chart',           // "ê·¸ë˜í”„ê°€ ë³´ì—¬ì£¼ëŠ” ì¶”ì„¸ëŠ”?"
  DIAGRAM = 'diagram',       // "ë‹¤ì´ì–´ê·¸ë¨ì—ì„œ í™”ì‚´í‘œì˜ ì˜ë¯¸ëŠ”?"
  EQUATION = 'equation',     // "ì´ ìˆ˜ì‹ì˜ ê²°ê³¼ëŠ”?"
  TABLE = 'table',          // "í‘œì—ì„œ ìµœëŒ€ê°’ì€?"
  TEXT_ONLY = 'text_only',  // "ê°œë…ì˜ ì •ì˜ëŠ”?" (ë¹„êµêµ°)
}
```

#### ì‹¤í—˜ ì¡°ê±´

```typescript
const conditions = [
  {
    name: 'Text-only RAG',
    useVision: false,
    useOCR: false,
  },
  {
    name: 'RAG + OCR',
    useVision: false,
    useOCR: true, // í…ìŠ¤íŠ¸ ì¶”ì¶œë§Œ
  },
  {
    name: 'RAG + Vision (Gemini)',
    useVision: true,
    useOCR: false,
  },
  {
    name: 'RAG + OCR + Vision',
    useVision: true,
    useOCR: true,
  },
];
```

#### í‰ê°€ ë°©ë²•

**1. ì •í™•ë„ í‰ê°€ (ì‚¬ëŒ í‰ê°€)**
```typescript
interface HumanEvaluation {
  questionId: string;
  answer: string;
  ratings: {
    factualAccuracy: number;  // 1-5: ì‚¬ì‹¤ ì •í™•ì„±
    relevance: number;         // 1-5: ì§ˆë¬¸ê³¼ì˜ ê´€ë ¨ì„±
    completeness: number;      // 1-5: ë‹µë³€ ì™„ì„±ë„
    usefulness: number;        // 1-5: ìœ ìš©ì„±
  };
  overallScore: number;        // 1-5
}

// 3ëª…ì˜ í‰ê°€ìê°€ ë…ë¦½ì ìœ¼ë¡œ í‰ê°€
// Inter-rater reliability ê³„ì‚° (Krippendorff's alpha)
```

**2. ìë™ í‰ê°€**
```typescript
// LLMì„ judgeë¡œ ì‚¬ìš© (GPT-4)
async function llmAsJudge(
  question: string,
  answer: string,
  groundTruth: string,
): Promise<number> {
  const prompt = `
    Question: ${question}
    Ground Truth: ${groundTruth}
    Answer: ${answer}
    
    Rate the answer's quality from 1-5:
    1: Completely incorrect
    2: Mostly incorrect
    3: Partially correct
    4: Mostly correct
    5: Completely correct
    
    Provide only the number.
  `;
  
  const response = await openai.chat.completions.create({
    model: 'gpt-4',
    messages: [{ role: 'user', content: prompt }],
  });
  
  return parseInt(response.choices[0].message.content);
}
```

**3. Citation ì •í™•ë„**
```typescript
function evaluateCitationAccuracy(
  citations: Citation[],
  relevantPages: number[],
): number {
  const citedPages = new Set(citations.map(c => c.pageNumber));
  const relevant = new Set(relevantPages);
  
  const intersection = new Set([...citedPages].filter(x => relevant.has(x)));
  
  // F1 score
  const precision = intersection.size / citedPages.size;
  const recall = intersection.size / relevant.size;
  
  return 2 * (precision * recall) / (precision + recall);
}
```

### ğŸ“ˆ ì˜ˆìƒ ê²°ê³¼

```
ì§ˆë¬¸ ìœ í˜•ë³„ ì •í™•ë„ í–¥ìƒ:

CHART ì§ˆë¬¸:
- Text-only: 45%
- + OCR: 55%
- + Vision: 85%
- + Both: 90%

EQUATION ì§ˆë¬¸:
- Text-only: 40%
- + OCR: 70%
- + Vision: 75%
- + Both: 85%

TEXT_ONLY ì§ˆë¬¸:
- Text-only: 80%
- + OCR: 82%
- + Vision: 81%
- + Both: 83%
```

### ë¹„ìš© ë¶„ì„

```typescript
interface CostAnalysis {
  condition: string;
  costPerQuestion: number;
  accuracy: number;
  costPerCorrectAnswer: number;
}

// ì˜ˆìƒ:
// Text-only: $0.01/question, 70% ì •í™•ë„ â†’ $0.014/correct
// + Vision: $0.05/question, 85% ì •í™•ë„ â†’ $0.059/correct
```

---

## ì‹¤í—˜ 4: ê°œì¸í™” í•™ìŠµ íš¨ê³¼ ë¶„ì„

### ğŸ“Š ì—°êµ¬ ì§ˆë¬¸

**RQ1**: ê°œì¸í™”ëœ ìš”ì•½/ì¶”ì²œì´ í•™ìŠµ íš¨ê³¼ë¥¼ í–¥ìƒì‹œí‚¤ëŠ”ê°€?

**RQ2**: ì–´ë–¤ í•™ìŠµ íŒ¨í„´ íŠ¹ì„±ì´ ê°œì¸í™” íš¨ê³¼ë¥¼ ê·¹ëŒ€í™”í•˜ëŠ”ê°€?

### ğŸ¯ ê°€ì„¤

- **H1**: ê°œì¸í™” ê·¸ë£¹ì´ ëŒ€ì¡°êµ° ëŒ€ë¹„ í•™ìŠµ ì‹œê°„ 20% ë‹¨ì¶•
- **H2**: ê°œì¸í™” ê·¸ë£¹ì´ ì´í•´ë„ í…ŒìŠ¤íŠ¸ì—ì„œ 15% ë†’ì€ ì ìˆ˜
- **H3**: ê°œì¸í™” ê·¸ë£¹ì˜ ë§Œì¡±ë„ê°€ ëŒ€ì¡°êµ° ëŒ€ë¹„ 30% ë†’ìŒ

### ğŸ“ ì‹¤í—˜ ì„¤ê³„

#### ì°¸ê°€ì ëª¨ì§‘

```
ì´ 60ëª…ì˜ í•™ìƒ
- ì‹¤í—˜êµ° (ê°œì¸í™” ì‚¬ìš©): 30ëª…
- ëŒ€ì¡°êµ° (ì¼ë°˜ ì‹œìŠ¤í…œ): 30ëª…

ë¶„ì•¼:
- ì»´í“¨í„°ê³¼í•™ ì „ê³µ: 20ëª…
- ê³µí•™ ì „ê³µ: 20ëª…
- ìì—°ê³¼í•™ ì „ê³µ: 20ëª…

í•™ë…„:
- 2í•™ë…„: 20ëª…
- 3í•™ë…„: 20ëª…
- 4í•™ë…„: 20ëª…
```

#### ì‹¤í—˜ í”„ë¡œí† ì½œ

**Week 0: ì‚¬ì „ í‰ê°€**
```
1. ì§€ì‹ ìˆ˜ì¤€ í…ŒìŠ¤íŠ¸ (ì‚¬ì „ í‰ê°€)
2. í•™ìŠµ ìŠ¤íƒ€ì¼ ì„¤ë¬¸ (VARK ëª¨ë¸)
3. ì‹œìŠ¤í…œ ì‚¬ìš©ë²• êµìœ¡
```

**Week 1-4: í•™ìŠµ ê¸°ê°„**
```
ë§¤ì£¼:
- 2ê°œì˜ ê°•ì˜ ì‹œì²­ (ê° 60ë¶„)
- AI ì±—ë´‡ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸
- ì£¼ê°„ í€´ì¦ˆ (10ë¬¸ì œ)

ìˆ˜ì§‘ ë°ì´í„°:
- ì‹œì²­ ì‹œê°„, ì¼ì‹œì •ì§€ íšŸìˆ˜
- ë°˜ë³µ ì‹œì²­ êµ¬ê°„
- ì§ˆë¬¸ ë¹ˆë„ ë° ìœ í˜•
- í€´ì¦ˆ ì ìˆ˜
```

**Week 5: ì‚¬í›„ í‰ê°€**
```
1. ì§€ì‹ ìˆ˜ì¤€ í…ŒìŠ¤íŠ¸ (ì‚¬í›„ í‰ê°€)
2. ë§Œì¡±ë„ ì„¤ë¬¸ (SUS - System Usability Scale)
3. ì¸í„°ë·° (ì •ì„±ì  í”¼ë“œë°±)
```

#### ê°œì¸í™” ê¸°ëŠ¥

```typescript
interface PersonalizedFeatures {
  // 1. ì ì‘í˜• ìš”ì•½
  summaryStyle: 'brief' | 'detailed' | 'example-based';
  summaryLength: number; // ì‚¬ìš©ì ì„ í˜¸ì— ë”°ë¼ ì¡°ì ˆ
  
  // 2. ì•½ì  ë³´ì™„ ì¶”ì²œ
  weakTopics: string[];
  recommendedContent: string[];
  
  // 3. ìµœì  í•™ìŠµ ì‹œê°„ ì œì•ˆ
  optimalStudyTime: string; // "19:00-21:00"
  studySessionLength: number; // 25ë¶„ (í¬ëª¨ë„ë¡œ) vs 60ë¶„
  
  // 4. ë§ì¶¤í˜• í€´ì¦ˆ
  quizDifficulty: 'easy' | 'medium' | 'hard';
  focusAreas: string[];
  
  // 5. í•™ìŠµ ì§„ë„ ì‹œê°í™”
  progressDashboard: {
    completedTopics: string[];
    masteryLevel: Record<string, number>;
    estimatedTimeToComplete: number;
  };
}
```

#### í‰ê°€ ì§€í‘œ

**1. í•™ìŠµ íš¨ìœ¨**
```typescript
interface LearningEfficiency {
  totalStudyTime: number; // ë¶„
  contentCovered: number; // í˜ì´ì§€/ê°•ì˜ ìˆ˜
  testScore: number; // 0-100
  
  // íš¨ìœ¨ = (ì ìˆ˜ í–¥ìƒ / í•™ìŠµ ì‹œê°„)
  efficiency: number;
}
```

**2. ì§€ì‹ í–¥ìƒ**
```typescript
interface KnowledgeGain {
  preTestScore: number;
  postTestScore: number;
  gain: number; // post - pre
  normalizedGain: number; // (post - pre) / (100 - pre)
}
```

**3. ì‚¬ìš©ì ë§Œì¡±ë„**
```typescript
interface Satisfaction {
  sus: number; // System Usability Scale (0-100)
  nps: number; // Net Promoter Score (-100 to 100)
  
  ratings: {
    easeOfUse: number; // 1-5
    helpfulness: number;
    personalization: number;
    wouldRecommend: boolean;
  };
}
```

### ğŸ“Š í†µê³„ ë¶„ì„

```r
# R ìŠ¤í¬ë¦½íŠ¸
library(tidyverse)
library(lme4)

# 1. t-test (ì‹¤í—˜êµ° vs ëŒ€ì¡°êµ°)
t.test(experimental_group$gain, control_group$gain)

# 2. ANOVA (ì—¬ëŸ¬ ìš”ì¸ ë¶„ì„)
anova_model <- aov(gain ~ group + major + year, data = results)
summary(anova_model)

# 3. íšŒê·€ ë¶„ì„ (ì–´ë–¤ ìš”ì¸ì´ íš¨ê³¼ì— ì˜í–¥?)
regression_model <- lm(
  gain ~ group + initial_score + study_time + question_count,
  data = results
)
summary(regression_model)

# 4. íš¨ê³¼ í¬ê¸° (Cohen's d)
cohen.d(experimental_group$gain, control_group$gain)
```

---

## ì‹¤í—˜ 5: ì‚¬ìš©ì ê²½í—˜ í‰ê°€

### ğŸ“Š ì—°êµ¬ ì§ˆë¬¸

**RQ1**: AI ê¸°ëŠ¥ë“¤ì´ ì „ë°˜ì ì¸ ì‚¬ìš©ì ê²½í—˜ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ê°€?

**RQ2**: ì–´ë–¤ AI ê¸°ëŠ¥ì´ ê°€ì¥ ê°€ì¹˜ ìˆë‹¤ê³  ì¸ì‹ë˜ëŠ”ê°€?

### ğŸ¯ ë°©ë²•ë¡ 

#### 1. ì„¤ë¬¸ ì¡°ì‚¬ (Quantitative)

**System Usability Scale (SUS)**
```
10ê°œ ë¬¸í•­, 5ì  ì²™ë„

1. ì´ ì‹œìŠ¤í…œì„ ìì£¼ ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤
2. ì‹œìŠ¤í…œì´ ë¶ˆí•„ìš”í•˜ê²Œ ë³µì¡í•˜ë‹¤
3. ì‹œìŠ¤í…œì´ ì‚¬ìš©í•˜ê¸° ì‰½ë‹¤
...

ì ìˆ˜ ê³„ì‚°: 0-100 (68ì  ì´ìƒì´ í‰ê·  ì´ìƒ)
```

**Technology Acceptance Model (TAM)**
```typescript
interface TAMSurvey {
  perceivedUsefulness: number; // ìœ ìš©ì„± ì¸ì‹
  perceivedEaseOfUse: number; // ì‚¬ìš© ìš©ì´ì„± ì¸ì‹
  attitudeTowardUsing: number; // ì‚¬ìš© íƒœë„
  behavioralIntention: number; // ì‚¬ìš© ì˜ë„
}
```

**AI Feature Rating**
```typescript
const aiFeatures = [
  'AI ì±—ë´‡ (ì§ˆë¬¸ ë‹µë³€)',
  'ìë™ ìš”ì•½',
  'í€´ì¦ˆ ìƒì„±',
  'ìŒì„± ì¸ì‹/ì „ì‚¬',
  'ê°œì¸í™” ì¶”ì²œ',
  'ì‹¤ì‹œê°„ í˜‘ì—…',
];

// ê° ê¸°ëŠ¥ì— ëŒ€í•´:
// - ì‚¬ìš© ë¹ˆë„ (1-5)
// - ìœ ìš©ì„± (1-5)
// - ë§Œì¡±ë„ (1-5)
```

#### 2. ì¸í„°ë·° (Qualitative)

**ë°˜êµ¬ì¡°í™” ì¸í„°ë·° (30ë¶„)**
```
ì§ˆë¬¸ ì˜ˆì‹œ:

1. ê°€ì¥ ìœ ìš©í–ˆë˜ AI ê¸°ëŠ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?
2. ì–´ë–¤ ìƒí™©ì—ì„œ AI ì±—ë´‡ì„ ì‚¬ìš©í–ˆë‚˜ìš”?
3. AI ë‹µë³€ì´ ë„ì›€ì´ ì•ˆ ë˜ì—ˆë˜ ê²½ìš°ê°€ ìˆë‚˜ìš”?
4. ê°œì¸í™” ê¸°ëŠ¥ì´ ì‹¤ì œë¡œ íš¨ê³¼ê°€ ìˆì—ˆë‚˜ìš”?
5. ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì€ ë¬´ì—‡ì¸ê°€ìš”?
6. ë‹¤ë¥¸ í•™ìƒë“¤ì—ê²Œ ì¶”ì²œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?
```

**í¬ì»¤ìŠ¤ ê·¸ë£¹ (6-8ëª…, 90ë¶„)**
```
ì£¼ì œ:
- AI ê¸°ëŠ¥ì˜ ì¥ë‹¨ì 
- í•™ìŠµ íŒ¨í„´ì˜ ë³€í™”
- ì „í†µì  í•™ìŠµ vs AI ì§€ì› í•™ìŠµ
- ë¯¸ë˜ ê¸°ëŠ¥ ì•„ì´ë””ì–´
```

#### 3. í–‰ë™ ë¶„ì„ (Behavioral)

```typescript
interface UserBehavior {
  // ì‚¬ìš© íŒ¨í„´
  dailyActiveTime: number[];
  featureUsageFrequency: Record<string, number>;
  
  // ì°¸ì—¬ë„
  questionsAsked: number;
  quizzesTaken: number;
  collaborationSessions: number;
  
  // í•™ìŠµ íŒ¨í„´
  averageSessionLength: number;
  pausePoints: number[]; // ì–´ë””ì„œ ë©ˆì·„ëŠ”ì§€
  repeatSections: number[]; // ë°˜ë³µ í•™ìŠµ êµ¬ê°„
  
  // ì„±ê³¼
  quizScores: number[];
  improvementRate: number;
}
```

### ğŸ“Š ë¶„ì„ ë°©ë²•

**ì •ëŸ‰ ë¶„ì„:**
```python
import pandas as pd
import scipy.stats as stats

# 1. ê¸°ìˆ  í†µê³„
df['sus_score'].describe()

# 2. ìƒê´€ ë¶„ì„
correlation = df[['usefulness', 'ease_of_use', 'satisfaction']].corr()

# 3. íšŒê·€ ë¶„ì„
from sklearn.linear_model import LinearRegression

X = df[['usefulness', 'ease_of_use', 'personalization']]
y = df['satisfaction']

model = LinearRegression()
model.fit(X, y)

print(f"RÂ² = {model.score(X, y)}")
print(f"Coefficients: {model.coef_}")
```

**ì •ì„± ë¶„ì„:**
```python
# Thematic Analysis (ì£¼ì œ ë¶„ì„)

# 1. ì¸í„°ë·° ì „ì‚¬ë³¸ ì½”ë”©
codes = {
    'positive': ['ìœ ìš©í•˜ë‹¤', 'ë„ì›€ì´ ëœë‹¤', 'ì¢‹ë‹¤'],
    'negative': ['ë¶ˆí¸í•˜ë‹¤', 'ë¶€ì •í™•í•˜ë‹¤', 'ëŠë¦¬ë‹¤'],
    'suggestions': ['~í•˜ë©´ ì¢‹ê² ë‹¤', 'ê°œì„ ', 'ì¶”ê°€'],
}

# 2. ì£¼ì œ ì¶”ì¶œ
themes = [
    'ì •í™•ë„ì™€ ì‹ ë¢°ì„±',
    'ì‚¬ìš© í¸ì˜ì„±',
    'í•™ìŠµ íš¨ê³¼',
    'ê°œì¸í™”',
    'í˜‘ì—… ê¸°ëŠ¥',
]

# 3. ë¹ˆë„ ë¶„ì„
for theme in themes:
    count = count_mentions(transcripts, theme)
    sentiment = analyze_sentiment(transcripts, theme)
```

---

## ğŸ“‹ ì „ì²´ ì‹¤í—˜ ì¼ì •

```
Week 1-2: ë°ì´í„° ìˆ˜ì§‘ ë° ì¤€ë¹„
- ê°•ì˜ ë…¹ìŒ ìˆ˜ì§‘
- Ground truth ìƒì„±
- ì§ˆë¬¸ ë°ì´í„°ì…‹ êµ¬ì¶•

Week 3-4: ì‹¤í—˜ 1 (Whisper vs Web Speech)
- ì „ì‚¬ ì‹¤í–‰
- WER ê³„ì‚°
- ê²°ê³¼ ë¶„ì„

Week 5-6: ì‹¤í—˜ 2 (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰)
- ê²€ìƒ‰ ì „ëµ í…ŒìŠ¤íŠ¸
- ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- ìµœì í™”

Week 7-8: ì‹¤í—˜ 3 (Multi-modal RAG)
- Vision API í†µí•©
- ì •í™•ë„ í‰ê°€
- ë¹„ìš© ë¶„ì„

Week 9-12: ì‹¤í—˜ 4 (ê°œì¸í™” íš¨ê³¼)
- ì‚¬ìš©ì ëª¨ì§‘
- 4ì£¼ í•™ìŠµ ê¸°ê°„
- ì‚¬ì „/ì‚¬í›„ í‰ê°€

Week 13-14: ì‹¤í—˜ 5 (UX í‰ê°€)
- ì„¤ë¬¸ ì¡°ì‚¬
- ì¸í„°ë·° ìˆ˜í–‰
- ë¶„ì„

Week 15-16: ë…¼ë¬¸ ì‘ì„±
- ê²°ê³¼ ì •ë¦¬
- ì‹œê°í™”
- ì´ˆê³  ì‘ì„±

Week 17-18: ë¦¬ë·° ë° ìˆ˜ì •
- ë™ë£Œ ë¦¬ë·°
- í”¼ë“œë°± ë°˜ì˜
- ìµœì¢… ì œì¶œ
```

---

## ğŸ“Š ì˜ˆìƒ ë…¼ë¬¸ êµ¬ì¡°

```
Title: "SyncNapse: An AI-Enhanced Collaborative Learning Platform 
        for Real-time Lecture Note Generation"

Abstract (250 words)
- Background, Methods, Results, Conclusion

1. Introduction (2 pages)
   - Motivation
   - Research Questions
   - Contributions

2. Related Work (3 pages)
   - Speech Recognition in Education
   - RAG Systems
   - Personalized Learning
   - Collaborative Learning Platforms

3. System Design (4 pages)
   - Architecture
   - AI Components
   - Implementation

4. Experiments (8 pages)
   4.1 Speech Recognition Evaluation
   4.2 Hybrid Search Evaluation
   4.3 Multi-modal RAG Evaluation
   4.4 Personalization Effect Study
   4.5 User Experience Study

5. Results (6 pages)
   - Quantitative Results
   - Qualitative Findings
   - Discussion

6. Limitations (1 page)

7. Conclusion & Future Work (1 page)

References (2 pages)

Total: ~25 pages
```

---

## ğŸ“ í†µê³„ì  ìœ ì˜ì„±

### Power Analysis (ê²€ì •ë ¥ ë¶„ì„)

```r
library(pwr)

# t-testì— í•„ìš”í•œ ìƒ˜í”Œ í¬ê¸°
# íš¨ê³¼ í¬ê¸° d = 0.5 (ì¤‘ê°„)
# ìœ ì˜ìˆ˜ì¤€ Î± = 0.05
# ê²€ì •ë ¥ 1-Î² = 0.80

pwr.t.test(
  d = 0.5,
  sig.level = 0.05,
  power = 0.80,
  type = "two.sample"
)

# ê²°ê³¼: ê·¸ë£¹ë‹¹ n â‰ˆ 64ëª… í•„ìš”
```

### ë‹¤ì¤‘ ë¹„êµ ë³´ì •

```r
# Bonferroni ë³´ì •
alpha_adjusted = 0.05 / number_of_tests

# ì˜ˆ: 5ê°œ ì‹¤í—˜ â†’ Î± = 0.05 / 5 = 0.01
```

---

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì‹¤í—˜ ì‹œì‘ ì „
- [ ] IRB ìŠ¹ì¸ (ì‚¬ëŒ ëŒ€ìƒ ì—°êµ¬)
- [ ] ì°¸ê°€ì ë™ì˜ì„œ
- [ ] ë°ì´í„° ìˆ˜ì§‘ ê³„íš
- [ ] í‰ê°€ ë„êµ¬ ì¤€ë¹„
- [ ] íŒŒì¼ëŸ¿ í…ŒìŠ¤íŠ¸

### ì‹¤í—˜ ì¤‘
- [ ] ë°ì´í„° ë°±ì—…
- [ ] ì¤‘ê°„ ì ê²€
- [ ] ì´ìƒì¹˜ í™•ì¸
- [ ] ì°¸ê°€ì ë¬¸ì˜ ëŒ€ì‘

### ì‹¤í—˜ í›„
- [ ] ë°ì´í„° ì •ì œ
- [ ] í†µê³„ ë¶„ì„
- [ ] ì‹œê°í™”
- [ ] ë…¼ë¬¸ ì‘ì„±
- [ ] ì½”ë“œ/ë°ì´í„° ê³µê°œ (ì˜µì…˜)

---

**ì‘ì„±ì¼**: 2025-12-07  
**ë²„ì „**: 1.0  
**ì—°ë½ì²˜**: AI Research Team

