# AI ê¸°ëŠ¥ êµ¬í˜„ ê°€ì´ë“œ

> ì‹¤ì œ ì½”ë“œ êµ¬í˜„ì„ ìœ„í•œ ë‹¨ê³„ë³„ ê°€ì´ë“œ

## ğŸ¯ Priority 1: Whisper í†µí•© (ìŒì„± ì¸ì‹ ê°œì„ )

### ì˜ˆìƒ ì‘ì—… ì‹œê°„: 1-2ì£¼

### 1ë‹¨ê³„: OpenAI SDK ì„¤ì¹˜

```bash
cd backend
npm install openai
npm install @types/node --save-dev
```

### 2ë‹¨ê³„: Whisper Service ìƒì„±

**íŒŒì¼**: `backend/src/modules/transcription/whisper.service.ts`

```typescript
import { Injectable, Logger } from '@nestjs/common';
import OpenAI from 'openai';
import { Readable } from 'stream';

export interface WhisperTranscriptionResult {
  text: string;
  segments: WhisperSegment[];
  language: string;
  duration: number;
}

export interface WhisperSegment {
  id: number;
  start: number;
  end: number;
  text: string;
  words?: WhisperWord[];
}

export interface WhisperWord {
  word: string;
  start: number;
  end: number;
}

@Injectable()
export class WhisperService {
  private readonly logger = new Logger(WhisperService.name);
  private readonly openai: OpenAI;

  constructor() {
    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      this.logger.warn('OPENAI_API_KEY not set - Whisper features will not work');
    }
    this.openai = new OpenAI({ apiKey: apiKey || 'sk-placeholder' });
  }

  /**
   * ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì‚¬ (ì „ì²´ íŒŒì¼)
   */
  async transcribeFile(
    audioBuffer: Buffer,
    options?: {
      language?: string;
      prompt?: string; // ì „ë¬¸ ìš©ì–´ íŒíŠ¸
      temperature?: number;
    },
  ): Promise<WhisperTranscriptionResult> {
    try {
      this.logger.log('Transcribing audio file with Whisper...');

      // Bufferë¥¼ File ê°ì²´ë¡œ ë³€í™˜
      const file = new File([audioBuffer], 'audio.mp3', { type: 'audio/mpeg' });

      const response = await this.openai.audio.transcriptions.create({
        file: file,
        model: 'whisper-1',
        language: options?.language || 'ko',
        response_format: 'verbose_json',
        timestamp_granularities: ['word', 'segment'],
        prompt: options?.prompt,
        temperature: options?.temperature || 0,
      });

      return {
        text: response.text,
        segments: response.segments?.map((seg) => ({
          id: seg.id,
          start: seg.start,
          end: seg.end,
          text: seg.text,
          words: seg.words?.map((w) => ({
            word: w.word,
            start: w.start,
            end: w.end,
          })),
        })) || [],
        language: response.language || 'ko',
        duration: response.duration || 0,
      };
    } catch (error) {
      this.logger.error('Whisper transcription failed', error);
      throw error;
    }
  }

  /**
   * ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì „ì‚¬ (ì²­í¬ ë‹¨ìœ„)
   */
  async transcribeChunk(
    audioChunk: Buffer,
    previousContext?: string,
  ): Promise<string> {
    try {
      const file = new File([audioChunk], 'chunk.mp3', { type: 'audio/mpeg' });

      const response = await this.openai.audio.transcriptions.create({
        file: file,
        model: 'whisper-1',
        language: 'ko',
        prompt: previousContext, // ì´ì „ ë¬¸ë§¥ ì œê³µ
      });

      return response.text;
    } catch (error) {
      this.logger.error('Chunk transcription failed', error);
      return '';
    }
  }

  /**
   * ì „ë¬¸ ìš©ì–´ ì»¤ìŠ¤í„°ë§ˆì´ì§•ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
   */
  generateCustomPrompt(subject: string, keywords: string[]): string {
    // ì „ë¬¸ ìš©ì–´ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ì‹œì¼œ ì¸ì‹ë¥  í–¥ìƒ
    const keywordStr = keywords.join(', ');
    return `This is a ${subject} lecture. Key terms: ${keywordStr}`;
  }
}
```

### 3ë‹¨ê³„: Audio Processor ê°œì„ 

**íŒŒì¼**: `backend/src/modules/queue/processors/audio.processor.ts`

```typescript
import { Injectable, Logger } from '@nestjs/common';
import { TranscriptionService } from '../../transcription/transcription.service';
import { WhisperService } from '../../transcription/whisper.service';
import { StorageService } from '../../storage/storage.service';

@Injectable()
export class AudioProcessor {
  private readonly logger = new Logger(AudioProcessor.name);

  constructor(
    private readonly transcriptionService: TranscriptionService,
    private readonly whisperService: WhisperService,
    private readonly storageService: StorageService,
  ) {}

  async process(name: string, data: any): Promise<any> {
    this.logger.log(`Processing job of type ${name}...`);

    if (name === 'transcribe') {
      return this.handleWhisperTranscription(data);
    }

    this.logger.warn(`Unknown job name: ${name}`);
    return { result: 'skipped' };
  }

  private async handleWhisperTranscription(data: {
    sessionId: string;
    audioUrl: string;
    storageKey: string;
    subject?: string;
    keywords?: string[];
  }): Promise<any> {
    const { sessionId, storageKey, subject, keywords } = data;

    this.logger.log(`[Whisper] Starting transcription for session: ${sessionId}`);

    try {
      // 1. Storageì—ì„œ ì˜¤ë””ì˜¤ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
      const fileStream = await this.storageService.getFileStream(storageKey);
      const audioBuffer = Buffer.isBuffer(fileStream.body)
        ? fileStream.body
        : Buffer.from(await fileStream.body.transformToByteArray());

      // 2. ì „ë¬¸ ìš©ì–´ í”„ë¡¬í”„íŠ¸ ìƒì„± (ì˜µì…˜)
      const prompt = keywords
        ? this.whisperService.generateCustomPrompt(subject || 'general', keywords)
        : undefined;

      // 3. Whisperë¡œ ì „ì‚¬
      const result = await this.whisperService.transcribeFile(audioBuffer, {
        language: 'ko',
        prompt,
      });

      // 4. DBì— ì €ì¥
      await this.transcriptionService.saveWhisperResult(sessionId, result);

      this.logger.log(`[Whisper] Transcription completed for session: ${sessionId}`);
      return { result: 'success', sessionId, segmentCount: result.segments.length };
    } catch (error) {
      this.logger.error(`[Whisper] Transcription failed for session: ${sessionId}`, error);
      throw error;
    }
  }
}
```

### 4ë‹¨ê³„: TranscriptionServiceì— Whisper ê²°ê³¼ ì €ì¥ ë©”ì„œë“œ ì¶”ê°€

**íŒŒì¼**: `backend/src/modules/transcription/transcription.service.ts`ì— ì¶”ê°€

```typescript
import { WhisperTranscriptionResult } from './whisper.service';

// ... existing code ...

async saveWhisperResult(
  sessionId: string,
  result: WhisperTranscriptionResult,
): Promise<void> {
  // ì„¸ê·¸ë¨¼íŠ¸ë¥¼ TranscriptionSegmentë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
  for (const segment of result.segments) {
    await this.prisma.transcriptionSegment.create({
      data: {
        sessionId: sessionId,
        startTime: segment.start,
        endTime: segment.end,
        text: segment.text,
        confidence: 0.95, // WhisperëŠ” confidenceë¥¼ ì œê³µí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’
        language: result.language,
        words: segment.words
          ? {
              create: segment.words.map((word, index) => ({
                word: word.word,
                startTime: word.start,
                endTime: word.end,
                confidence: 0.95,
              })),
            }
          : undefined,
      },
    });
  }

  // ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
  await this.prisma.transcriptionSession.update({
    where: { id: sessionId },
    data: {
      status: 'completed',
      duration: result.duration,
      language: result.language,
    },
  });
}
```

### 5ë‹¨ê³„: í™˜ê²½ ë³€ìˆ˜ ì¶”ê°€

```bash
# .env.devì— ì¶”ê°€
OPENAI_API_KEY=sk-your-key-here
```

### 6ë‹¨ê³„: í…ŒìŠ¤íŠ¸

```typescript
// backend/src/modules/transcription/whisper.service.spec.ts
import { Test, TestingModule } from '@nestjs/testing';
import { WhisperService } from './whisper.service';
import * as fs from 'fs';
import * as path from 'path';

describe('WhisperService', () => {
  let service: WhisperService;

  beforeEach(async () => {
    const module: TestingModule = await Test.createTestingModule({
      providers: [WhisperService],
    }).compile();

    service = module.get<WhisperService>(WhisperService);
  });

  it('should transcribe audio file', async () => {
    // í…ŒìŠ¤íŠ¸ìš© ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ
    const audioPath = path.join(__dirname, '../../../test/fixtures/sample.mp3');
    const audioBuffer = fs.readFileSync(audioPath);

    const result = await service.transcribeFile(audioBuffer, {
      language: 'ko',
    });

    expect(result.text).toBeDefined();
    expect(result.segments.length).toBeGreaterThan(0);
    expect(result.language).toBe('ko');
  });
});
```

---

## ğŸ¯ Priority 2: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ êµ¬í˜„

### ì˜ˆìƒ ì‘ì—… ì‹œê°„: 2-3ì£¼

### 1ë‹¨ê³„: í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
cd backend
npm install natural stopword
```

### 2ë‹¨ê³„: BM25 Search Service ìƒì„±

**íŒŒì¼**: `backend/src/modules/ai/services/bm25-search.service.ts`

```typescript
import { Injectable, Logger } from '@nestjs/common';
import * as natural from 'natural';
import * as stopword from 'stopword';

export interface BM25Document {
  id: string;
  text: string;
  metadata?: Record<string, any>;
}

export interface BM25Result {
  id: string;
  score: number;
  metadata?: Record<string, any>;
}

@Injectable()
export class BM25SearchService {
  private readonly logger = new Logger(BM25SearchService.name);
  private readonly tokenizer = new natural.WordTokenizer();
  
  // BM25 íŒŒë¼ë¯¸í„°
  private readonly k1 = 1.5;
  private readonly b = 0.75;

  /**
   * BM25 ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ê²€ìƒ‰
   */
  search(
    query: string,
    documents: BM25Document[],
    topK: number = 5,
  ): BM25Result[] {
    // 1. ì¿¼ë¦¬ í† í°í™” ë° ë¶ˆìš©ì–´ ì œê±°
    const queryTokens = this.preprocessText(query);
    
    if (queryTokens.length === 0) {
      return [];
    }

    // 2. ë¬¸ì„œ í† í°í™” ë° ì „ì²˜ë¦¬
    const docTokens = documents.map(doc => this.preprocessText(doc.text));
    
    // 3. í‰ê·  ë¬¸ì„œ ê¸¸ì´ ê³„ì‚°
    const avgDocLen = docTokens.reduce((sum, tokens) => sum + tokens.length, 0) / docTokens.length;
    
    // 4. IDF ê³„ì‚°
    const idf = this.calculateIDF(queryTokens, docTokens);
    
    // 5. ê° ë¬¸ì„œì— ëŒ€í•œ BM25 ìŠ¤ì½”ì–´ ê³„ì‚°
    const scores = documents.map((doc, idx) => {
      const score = this.calculateBM25Score(
        queryTokens,
        docTokens[idx],
        avgDocLen,
        idf,
      );
      
      return {
        id: doc.id,
        score,
        metadata: doc.metadata,
      };
    });
    
    // 6. ìŠ¤ì½”ì–´ ê¸°ì¤€ ì •ë ¬ ë° ìƒìœ„ Kê°œ ë°˜í™˜
    return scores
      .filter(s => s.score > 0)
      .sort((a, b) => b.score - a.score)
      .slice(0, topK);
  }

  /**
   * í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬: í† í°í™” + ë¶ˆìš©ì–´ ì œê±° + ì†Œë¬¸ì ë³€í™˜
   */
  private preprocessText(text: string): string[] {
    // í† í°í™”
    const tokens = this.tokenizer.tokenize(text.toLowerCase());
    
    if (!tokens) return [];
    
    // í•œêµ­ì–´ + ì˜ì–´ ë¶ˆìš©ì–´ ì œê±°
    const filtered = stopword.removeStopwords(tokens, [
      ...stopword.ko,
      ...stopword.en,
    ]);
    
    return filtered;
  }

  /**
   * IDF (Inverse Document Frequency) ê³„ì‚°
   */
  private calculateIDF(
    queryTokens: string[],
    docTokens: string[][],
  ): Map<string, number> {
    const idf = new Map<string, number>();
    const N = docTokens.length;
    
    for (const token of queryTokens) {
      // í•´ë‹¹ í† í°ì„ í¬í•¨í•œ ë¬¸ì„œ ê°œìˆ˜
      const df = docTokens.filter(tokens => tokens.includes(token)).length;
      
      // IDF ê³„ì‚°: log((N - df + 0.5) / (df + 0.5))
      idf.set(token, Math.log((N - df + 0.5) / (df + 0.5)));
    }
    
    return idf;
  }

  /**
   * BM25 ìŠ¤ì½”ì–´ ê³„ì‚°
   */
  private calculateBM25Score(
    queryTokens: string[],
    docTokens: string[],
    avgDocLen: number,
    idf: Map<string, number>,
  ): number {
    const docLen = docTokens.length;
    let score = 0;
    
    for (const token of queryTokens) {
      // ë¬¸ì„œ ë‚´ í† í° ë¹ˆë„
      const tf = docTokens.filter(t => t === token).length;
      
      // IDF ê°’
      const idfValue = idf.get(token) || 0;
      
      // BM25 ê³µì‹
      const numerator = tf * (this.k1 + 1);
      const denominator = tf + this.k1 * (1 - this.b + this.b * (docLen / avgDocLen));
      
      score += idfValue * (numerator / denominator);
    }
    
    return score;
  }
}
```

### 3ë‹¨ê³„: Hybrid Search Service ìƒì„±

**íŒŒì¼**: `backend/src/modules/ai/services/hybrid-search.service.ts`

```typescript
import { Injectable, Logger } from '@nestjs/common';
import { BM25SearchService, BM25Document, BM25Result } from './bm25-search.service';
import { Document } from 'llamaindex';

export interface HybridSearchResult {
  document: Document;
  score: number;
  vectorScore: number;
  keywordScore: number;
  metadata: Record<string, any>;
}

@Injectable()
export class HybridSearchService {
  private readonly logger = new Logger(HybridSearchService.name);

  // í•˜ì´ë¸Œë¦¬ë“œ ê°€ì¤‘ì¹˜
  private readonly VECTOR_WEIGHT = 0.6;
  private readonly KEYWORD_WEIGHT = 0.4;

  constructor(private readonly bm25Service: BM25SearchService) {}

  /**
   * ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ì™€ í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê²°í•©
   */
  async combineResults(
    query: string,
    documents: Document[],
    vectorResults: Array<{ node: any; score: number }>,
    topK: number = 5,
  ): Promise<HybridSearchResult[]> {
    // 1. BM25 í‚¤ì›Œë“œ ê²€ìƒ‰ ìˆ˜í–‰
    const bm25Docs: BM25Document[] = documents.map((doc, idx) => ({
      id: idx.toString(),
      text: doc.getText(),
      metadata: doc.metadata,
    }));

    const keywordResults = this.bm25Service.search(query, bm25Docs, topK * 2);

    // 2. ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì •ê·œí™”
    const vectorScoreMap = new Map<string, number>();
    const maxVectorScore = Math.max(...vectorResults.map(r => r.score), 1);
    
    vectorResults.forEach((result) => {
      const text = result.node.node?.text || result.node.text;
      vectorScoreMap.set(text, result.score / maxVectorScore);
    });

    // 3. í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ì •ê·œí™”
    const keywordScoreMap = new Map<string, number>();
    const maxKeywordScore = Math.max(...keywordResults.map(r => r.score), 1);
    
    keywordResults.forEach((result) => {
      const doc = documents[parseInt(result.id)];
      keywordScoreMap.set(doc.getText(), result.score / maxKeywordScore);
    });

    // 4. í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ ê³„ì‚°
    const combinedResults: HybridSearchResult[] = [];
    const seenTexts = new Set<string>();

    // ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
    for (const result of vectorResults) {
      const text = result.node.node?.text || result.node.text;
      if (seenTexts.has(text)) continue;
      seenTexts.add(text);

      const vectorScore = vectorScoreMap.get(text) || 0;
      const keywordScore = keywordScoreMap.get(text) || 0;
      const hybridScore = 
        this.VECTOR_WEIGHT * vectorScore + 
        this.KEYWORD_WEIGHT * keywordScore;

      const doc = documents.find(d => d.getText() === text);
      if (doc) {
        combinedResults.push({
          document: doc,
          score: hybridScore,
          vectorScore,
          keywordScore,
          metadata: doc.metadata,
        });
      }
    }

    // í‚¤ì›Œë“œ ê²€ìƒ‰ì—ì„œë§Œ ë‚˜ì˜¨ ê²°ê³¼ ì¶”ê°€
    for (const result of keywordResults) {
      const doc = documents[parseInt(result.id)];
      const text = doc.getText();
      
      if (seenTexts.has(text)) continue;
      seenTexts.add(text);

      const vectorScore = vectorScoreMap.get(text) || 0;
      const keywordScore = keywordScoreMap.get(text) || 0;
      const hybridScore = 
        this.VECTOR_WEIGHT * vectorScore + 
        this.KEYWORD_WEIGHT * keywordScore;

      combinedResults.push({
        document: doc,
        score: hybridScore,
        vectorScore,
        keywordScore,
        metadata: doc.metadata,
      });
    }

    // 5. í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ ê¸°ì¤€ ì •ë ¬ ë° ìƒìœ„ Kê°œ ë°˜í™˜
    return combinedResults
      .sort((a, b) => b.score - a.score)
      .slice(0, topK);
  }

  /**
   * ì¿¼ë¦¬ ìœ í˜•ì— ë”°ë¼ ê°€ì¤‘ì¹˜ ë™ì  ì¡°ì •
   */
  adjustWeights(query: string): { vectorWeight: number; keywordWeight: number } {
    // ì •í™•í•œ í‚¤ì›Œë“œ ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš° (ì¸ìš©ë¶€í˜¸, ì „ë¬¸ ìš©ì–´ ë“±)
    if (query.includes('"') || query.includes("'")) {
      return { vectorWeight: 0.3, keywordWeight: 0.7 };
    }

    // ê°œë…ì  ì§ˆë¬¸ (ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ ì¤‘ìš”)
    if (query.includes('ë¬´ì—‡') || query.includes('ì–´ë–»ê²Œ') || query.includes('ì™œ')) {
      return { vectorWeight: 0.7, keywordWeight: 0.3 };
    }

    // ê¸°ë³¸ê°’
    return { vectorWeight: 0.6, keywordWeight: 0.4 };
  }
}
```

### 4ë‹¨ê³„: RAG Engineì— í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í†µí•©

**íŒŒì¼**: `backend/src/modules/ai/services/rag-engine.service.ts` ìˆ˜ì •

```typescript
// ... existing imports ...
import { HybridSearchService } from './hybrid-search.service';

@Injectable()
export class RagEngineService {
  // ... existing code ...

  constructor(
    private readonly prisma: PrismaService,
    private readonly storageService: StorageService,
    private readonly hybridSearchService: HybridSearchService, // ì¶”ê°€
  ) {
    // ... existing code ...
  }

  async queryWithRag(
    lectureNoteId: string,
    query: string,
    mode: ChatMode,
  ): Promise<{ answer: string; citations: Citation[] }> {
    // 1. ë¬¸ì„œ ìˆ˜ì§‘
    const documents = await this.fetchNoteDocuments(lectureNoteId);

    if (documents.length === 0) {
      throw new Error('No content found in this note');
    }

    // 2. ë²¡í„° ì¸ë±ìŠ¤ ìƒì„±
    const index = await VectorStoreIndex.fromDocuments(documents);

    // 3. ë²¡í„° ê²€ìƒ‰ ì¿¼ë¦¬ ì—”ì§„ ìƒì„±
    const queryEngine = index.asQueryEngine({
      similarityTopK: 10, // í•˜ì´ë¸Œë¦¬ë“œë¥¼ ìœ„í•´ ë” ë§ì´ ê°€ì ¸ì˜´
    });

    // 4. ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
    const vectorResponse = await queryEngine.query({ query });
    const vectorResults = vectorResponse.sourceNodes || [];

    // 5. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì ìš© (ì‹ ê·œ)
    const hybridResults = await this.hybridSearchService.combineResults(
      query,
      documents,
      vectorResults.map(node => ({
        node: node,
        score: node.score || 0,
      })),
      5, // ìµœì¢… TOP-5
    );

    // 6. í•˜ì´ë¸Œë¦¬ë“œ ê²°ê³¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    const context = hybridResults
      .map((result, idx) => {
        const meta = result.metadata;
        return `[${idx + 1}] (Source: ${meta.type}, Page: ${meta.pageNumber || 'N/A'})\n${result.document.getText()}`;
      })
      .join('\n\n');

    // 7. í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ë‹µë³€ ìƒì„±
    const prompt = this.buildPrompt(query, context, mode);
    const answer = await this.generateAnswer(prompt);

    // 8. Citations ìƒì„±
    const citations = hybridResults.map((result, idx) => ({
      pageNumber: result.metadata.pageNumber || null,
      startSec: result.metadata.timestamp || null,
      endSec: null,
      score: result.score,
      text: result.document.getText().substring(0, 200),
    }));

    return { answer, citations };
  }

  // ... rest of existing code ...
}
```

### 5ë‹¨ê³„: Moduleì— ë“±ë¡

**íŒŒì¼**: `backend/src/modules/ai/ai.module.ts`

```typescript
import { Module } from '@nestjs/common';
import { AiController } from './ai.controller';
import { AiService } from './ai.service';
import { RagEngineService } from './services/rag-engine.service';
import { BM25SearchService } from './services/bm25-search.service';
import { HybridSearchService } from './services/hybrid-search.service';
import { DbModule } from '../db/db.module';
import { StorageModule } from '../storage/storage.module';

@Module({
  imports: [DbModule, StorageModule],
  controllers: [AiController],
  providers: [
    AiService,
    RagEngineService,
    BM25SearchService, // ì¶”ê°€
    HybridSearchService, // ì¶”ê°€
  ],
  exports: [AiService, RagEngineService],
})
export class AiModule {}
```

---

## ğŸ¯ Priority 3: Gemini Vision í†µí•© (Multi-modal)

### ì˜ˆìƒ ì‘ì—… ì‹œê°„: 1-2ì£¼

### 1ë‹¨ê³„: Vision Service ìƒì„±

**íŒŒì¼**: `backend/src/modules/ai/services/vision.service.ts`

```typescript
import { Injectable, Logger } from '@nestjs/common';
import { GoogleGenerativeAI } from '@google/generative-ai';

export interface VisionAnalysisResult {
  description: string;
  extractedText?: string;
  detectedObjects?: string[];
  chartAnalysis?: {
    type: string; // bar, line, pie, etc.
    data: any;
    insights: string;
  };
}

@Injectable()
export class VisionService {
  private readonly logger = new Logger(VisionService.name);
  private readonly genAI: GoogleGenerativeAI;

  constructor() {
    const apiKey = process.env.GEMINI_API_KEY || '';
    this.genAI = new GoogleGenerativeAI(apiKey);
  }

  /**
   * ì´ë¯¸ì§€ ë¶„ì„: ì¼ë°˜ ì„¤ëª… ìƒì„±
   */
  async analyzeImage(
    imageBuffer: Buffer,
    prompt?: string,
  ): Promise<VisionAnalysisResult> {
    try {
      const model = this.genAI.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });

      const imagePart = {
        inlineData: {
          data: imageBuffer.toString('base64'),
          mimeType: 'image/png',
        },
      };

      const defaultPrompt = `Analyze this image and describe what you see in detail. 
        If there are charts, graphs, or diagrams, explain them.
        If there is text, extract it.`;

      const result = await model.generateContent([
        prompt || defaultPrompt,
        imagePart,
      ]);

      const response = await result.response;
      const text = response.text();

      return {
        description: text,
      };
    } catch (error) {
      this.logger.error('Image analysis failed', error);
      throw error;
    }
  }

  /**
   * ì°¨íŠ¸/ê·¸ë˜í”„ ë¶„ì„
   */
  async analyzeChart(imageBuffer: Buffer): Promise<VisionAnalysisResult> {
    const prompt = `Analyze this chart or graph. Provide:
      1. Chart type (bar, line, pie, scatter, etc.)
      2. What data is being shown
      3. Key trends or insights
      4. Any notable patterns or outliers
      
      Format your response as JSON with keys: type, description, insights`;

    const result = await this.analyzeImage(imageBuffer, prompt);

    try {
      // JSON íŒŒì‹± ì‹œë„
      const jsonMatch = result.description.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const parsed = JSON.parse(jsonMatch[0]);
        return {
          description: result.description,
          chartAnalysis: parsed,
        };
      }
    } catch (e) {
      // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
    }

    return result;
  }

  /**
   * OCR: ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
   */
  async extractText(imageBuffer: Buffer): Promise<string> {
    const prompt = `Extract all visible text from this image. 
      Include text from diagrams, labels, and annotations.
      Preserve formatting where possible.`;

    const result = await this.analyzeImage(imageBuffer, prompt);
    return result.description;
  }

  /**
   * ìˆ˜ì‹ ì¸ì‹ (LaTeX ë³€í™˜)
   */
  async recognizeMath(imageBuffer: Buffer): Promise<string> {
    const prompt = `This image contains mathematical equations or formulas.
      Convert them to LaTeX format.
      If there are multiple equations, separate them with newlines.`;

    const result = await this.analyzeImage(imageBuffer, prompt);
    return result.description;
  }
}
```

### 2ë‹¨ê³„: RAG Engineì— Vision í†µí•©

```typescript
// rag-engine.service.tsì— ì¶”ê°€

async fetchNoteDocumentsWithVision(lectureNoteId: string): Promise<Document[]> {
  const documents = await this.fetchNoteDocuments(lectureNoteId);
  
  // PDF íŒŒì¼ì˜ ì´ë¯¸ì§€ í˜ì´ì§€ë„ ë¶„ì„
  const files = await this.prisma.file.findMany({
    where: { 
      noteId: lectureNoteId,
      fileType: { contains: 'pdf' },
    },
  });

  for (const file of files) {
    // PDF í˜ì´ì§€ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
    const pages = await this.prisma.page.findMany({
      where: { fileId: file.id },
    });

    for (const page of pages) {
      if (page.imageUrl) {
        try {
          // ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
          const imageStream = await this.storageService.getFileStream(page.storageKey);
          const imageBuffer = Buffer.from(await imageStream.body.transformToByteArray());

          // Vision APIë¡œ ë¶„ì„
          const analysis = await this.visionService.analyzeImage(imageBuffer);

          // ë¶„ì„ ê²°ê³¼ë¥¼ Documentë¡œ ì¶”ê°€
          const doc = new Document({
            text: `[ì´ë¯¸ì§€ ë¶„ì„ - Page ${page.pageNumber}]\n${analysis.description}`,
            metadata: {
              noteId: lectureNoteId,
              type: 'vision_analysis',
              fileId: file.id,
              pageNumber: page.pageNumber,
            },
          });

          documents.push(doc);
        } catch (error) {
          this.logger.error(`Failed to analyze image for page ${page.pageNumber}`, error);
        }
      }
    }
  }

  return documents;
}
```

---

## ğŸ“Š í‰ê°€ ë° ë²¤ì¹˜ë§ˆí‚¹

### í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

**íŒŒì¼**: `backend/scripts/evaluate-rag.ts`

```typescript
import { PrismaClient } from '@prisma/client';
import { RagEngineService } from '../src/modules/ai/services/rag-engine.service';

interface EvaluationResult {
  question: string;
  groundTruth: string;
  predicted: string;
  accuracy: number;
  responseTime: number;
}

const testQuestions = [
  {
    question: "ë°ì´í„° êµ¬ì¡°ë€ ë¬´ì—‡ì¸ê°€?",
    groundTruth: "ì»´í“¨í„°ì—ì„œ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥í•˜ê³  ê´€ë¦¬í•˜ê¸° ìœ„í•œ ë°©ë²•",
  },
  {
    question: "ìŠ¤íƒê³¼ íì˜ ì°¨ì´ì ì€?",
    groundTruth: "ìŠ¤íƒì€ LIFO, íëŠ” FIFO êµ¬ì¡°",
  },
  // ... ë” ë§ì€ ì§ˆë¬¸ ì¶”ê°€
];

async function evaluateRAG() {
  const prisma = new PrismaClient();
  const ragService = new RagEngineService(prisma, /* ... */);

  const results: EvaluationResult[] = [];

  for (const test of testQuestions) {
    const startTime = Date.now();
    
    const response = await ragService.queryWithRag(
      'test-note-id',
      test.question,
      'question',
    );
    
    const responseTime = Date.now() - startTime;

    // ê°„ë‹¨í•œ ì •í™•ë„ ì¸¡ì • (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë©”íŠ¸ë¦­ ì‚¬ìš©)
    const accuracy = calculateSimilarity(response.answer, test.groundTruth);

    results.push({
      question: test.question,
      groundTruth: test.groundTruth,
      predicted: response.answer,
      accuracy,
      responseTime,
    });
  }

  // ê²°ê³¼ ì¶œë ¥
  console.log('=== RAG Evaluation Results ===');
  console.log(`Total Questions: ${results.length}`);
  console.log(`Average Accuracy: ${results.reduce((sum, r) => sum + r.accuracy, 0) / results.length}`);
  console.log(`Average Response Time: ${results.reduce((sum, r) => sum + r.responseTime, 0) / results.length}ms`);
}

function calculateSimilarity(str1: string, str2: string): number {
  // Cosine similarity, Jaccard similarity ë“± ì‚¬ìš© ê°€ëŠ¥
  // ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ë‹¨ì–´ ì¼ì¹˜ìœ¨ë¡œ ê³„ì‚°
  const words1 = new Set(str1.toLowerCase().split(/\s+/));
  const words2 = new Set(str2.toLowerCase().split(/\s+/));
  
  const intersection = new Set([...words1].filter(x => words2.has(x)));
  const union = new Set([...words1, ...words2]);
  
  return intersection.size / union.size;
}

evaluateRAG();
```

---

## ğŸ§ª ì‹¤í—˜ ì„¤ê³„

### A/B í…ŒìŠ¤íŠ¸ ì„¤ì •

**íŒŒì¼**: `backend/src/modules/ai/services/ab-test.service.ts`

```typescript
import { Injectable } from '@nestjs/common';

@Injectable()
export class ABTestService {
  /**
   * ì‚¬ìš©ìë¥¼ A/B ê·¸ë£¹ì— í• ë‹¹
   */
  assignGroup(userId: string): 'A' | 'B' {
    // ì‚¬ìš©ì IDì˜ í•´ì‹œê°’ìœ¼ë¡œ ì¼ê´€ì„± ìˆê²Œ í• ë‹¹
    const hash = this.simpleHash(userId);
    return hash % 2 === 0 ? 'A' : 'B';
  }

  /**
   * ì‹¤í—˜ ê²°ê³¼ ë¡œê¹…
   */
  async logExperiment(data: {
    userId: string;
    group: 'A' | 'B';
    feature: string;
    metric: string;
    value: number;
  }) {
    // DBì— ì €ì¥ ë˜ëŠ” ë¶„ì„ ë„êµ¬ë¡œ ì „ì†¡
    // ì˜ˆ: Mixpanel, Amplitude, Google Analytics
  }

  private simpleHash(str: string): number {
    let hash = 0;
    for (let i = 0; i < str.length; i++) {
      hash = (hash << 5) - hash + str.charCodeAt(i);
      hash |= 0;
    }
    return Math.abs(hash);
  }
}
```

---

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### AI ê¸°ëŠ¥ ëª¨ë‹ˆí„°ë§

**íŒŒì¼**: `backend/src/modules/ai/ai.interceptor.ts`

```typescript
import {
  Injectable,
  NestInterceptor,
  ExecutionContext,
  CallHandler,
  Logger,
} from '@nestjs/common';
import { Observable } from 'rxjs';
import { tap } from 'rxjs/operators';

@Injectable()
export class AIMonitoringInterceptor implements NestInterceptor {
  private readonly logger = new Logger('AI-Monitoring');

  intercept(context: ExecutionContext, next: CallHandler): Observable<any> {
    const request = context.switchToHttp().getRequest();
    const { method, url, body } = request;
    const startTime = Date.now();

    return next.handle().pipe(
      tap({
        next: (data) => {
          const duration = Date.now() - startTime;
          
          // ì„±ê³µ ë¡œê¹…
          this.logger.log({
            method,
            url,
            duration,
            status: 'success',
            question: body?.question,
            answerLength: data?.answer?.length,
            citationCount: data?.citations?.length,
          });

          // ë©”íŠ¸ë¦­ ì „ì†¡ (Prometheus, CloudWatch ë“±)
          // metrics.recordAIRequest(duration, 'success');
        },
        error: (error) => {
          const duration = Date.now() - startTime;
          
          // ì—ëŸ¬ ë¡œê¹…
          this.logger.error({
            method,
            url,
            duration,
            status: 'error',
            error: error.message,
          });

          // metrics.recordAIRequest(duration, 'error');
        },
      }),
    );
  }
}
```

---

## ğŸ” ë‹¤ìŒ ë‹¨ê³„

1. **Whisper í†µí•© ì™„ë£Œ** â†’ ìŒì„± ì¸ì‹ ì •í™•ë„ ì¸¡ì •
2. **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸** â†’ MRR, NDCG ê³„ì‚°
3. **Vision API ì‹¤í—˜** â†’ ì´ë¯¸ì§€ ë¶„ì„ í’ˆì§ˆ í‰ê°€
4. **A/B í…ŒìŠ¤íŠ¸ ì‹œì‘** â†’ ì‚¬ìš©ì ë§Œì¡±ë„ ë¹„êµ
5. **ë…¼ë¬¸ ì‘ì„± ì‹œì‘** â†’ ì‹¤í—˜ ê²°ê³¼ ì •ë¦¬

## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- [OpenAI Whisper API Docs](https://platform.openai.com/docs/guides/speech-to-text)
- [BM25 ì•Œê³ ë¦¬ì¦˜ ì„¤ëª…](https://en.wikipedia.org/wiki/Okapi_BM25)
- [Gemini Vision API Docs](https://ai.google.dev/tutorials/python_quickstart#multi-modal)
- [RAG í‰ê°€ ë©”íŠ¸ë¦­](https://docs.llamaindex.ai/en/stable/examples/evaluation/retrieval_evals/)

---

**ì—…ë°ì´íŠ¸**: 2025-12-07  
**ë²„ì „**: 1.0

